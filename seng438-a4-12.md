**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 â€“ Mutation Testing and Web app testing**

| Group \#:      |  12   |
| -------------- | --- |
| Student Names: | Shaila Aktar    |
| Student Names: | Muhammad Arij Ashar  |
| Student Names: | Mohammad Sadat Mohtasim   |
| Student Names: | Gaumit Kauts |

# Introduction


# Analysis of 10 Mutants of the Range class 
## Range.contains()
<img width="955" alt="contains" src="https://user-images.githubusercontent.com/90587576/225849035-7aec740d-9f4e-411e-95ac-e32b7a209e93.png">

## Range.expandToInclude()
<img width="952" alt="expandToInclude" src="https://user-images.githubusercontent.com/90587576/225849127-891c981e-f5f2-4219-9eea-02d5c53eac9d.png">

## Range.scale()
<img width="957" alt="scale" src="https://user-images.githubusercontent.com/90587576/225849149-dce601b7-a8db-4503-801f-6d94d5bf56ee.png">


# Report all the statistics and the mutation score for each test class
## Range statistics from Lab 03
<img width="843" alt="Screen Shot 2023-03-17 at 2 09 38 AM" src="https://user-images.githubusercontent.com/90587576/225849551-f1fb1e99-c004-44f9-bcb5-5ae9811a3113.png">

## Range statistics after adding more unit tests
<img width="836" alt="Screen Shot 2023-03-17 at 1 35 11 AM" src="https://user-images.githubusercontent.com/90587576/225849386-37ae5ad0-1e76-4269-8fdb-62aa8b69f72a.png">

## DataUtilities statistics from Lab 03
<img width="844" alt="Screen Shot 2023-03-17 at 2 56 58 PM" src="https://user-images.githubusercontent.com/90587576/226056267-8ef995de-d874-46c5-9e09-c048c1e05b67.png">

## DataUtilities statistics after adding more unit tests
<img width="838" alt="Screen Shot 2023-03-17 at 3 20 41 PM" src="https://user-images.githubusercontent.com/90587576/226056295-749d9080-c4cb-4c42-a0c7-b5ae15b589fc.png">


# Analysis drawn on the effectiveness of each of the test classes
Our mutation testing results indicate a noticeably greater efficacy for the Range and DataUtilities Classes. Range class's mutation coverage score improved by 28%, bringing the overall mutation coverage score up to 74%. The fact that our tests exceeded the requisite 10% increase specified at the markdown file demonstrates the lab's performance. These advancements in mutation testing aid in the detection of potential flaws and problems in the source code, which eventually results in a more reliable and practical software system. It's also crucial to keep in mind that as our mutation testing's coverage expands, it gets tougher to find mutations.
# A discussion on the effect of equivalent mutants on mutation score accuracy
Equivalent mutations are fundamentally distinct syntactically but semantically from the original code. Changing inequality signs or performing basic mathematical operations can be used to produce mutants that have the exact same logic as the originals, even if they are not expressed in the same way. Using analogous mutants will provide the developer with additional information on the calibre of his or her test suit because mutations are meant to replicate potential human faults or basic logical problems. Using that, they ought to be able to identify the unit test's shortcomings and, as a result, rectify them for a higher-quality end result.

Yet, if employed improperly, comparable mutants might artificially increase or deflate the accuracy of the testing suite. Equivalent mutations need to be utilised cautiously because they are just various ways of applying the same reasoning in the code. Coming back to the previous example, if we assume that each of the ten mutations is similar, then one test case would be sufficient to obtain a 100% mutation score, which may indicate a very high score and a programme that has been tested to the utmost extent. Nevertheless, not all potential paths have been explored, and the programme is not yet suitable for production.

Same to the previous situation, if all mutations are identical and the test suite does not cover the mutations, the mutation score may be 0%. As a result, while analogous mutations are important tools for evaluating the quality of the current mutations that have been used, they do have certain limitations that should be taken into account since they may result in inaccurate mutation ratings.

# A discussion of what could have been done to improve the mutation score of the test suites
The mutation score would increase overall if multiple mutants were killed while developing a test case. Also, we started focusing on functions with less coverage because there was a higher likelihood of boosting the overall mutation score on those. Throughout this process, we were also able to boost the scores to respectable levels. Given that mutations are frequently very slight changes that we occasionally forget to verify, such as an inequality error on an if statement condition, it is not difficult to ensure that the formula's outputs are accurate in certain circumstances.

# Why do we need mutation testing? Advantages and disadvantages of mutation testing
Implementing mutation testing is primarily done to improve the testing process' efficacy and, as a result, the software's quality. We may evaluate the efficiency and test coverage of the JUnit tests created for the application by making minor modifications to the source code. An efficient test suite would have a high mutation score, indicating that the code was being thoroughly evaluated while being exposed to a wide range of inputs.


Some of the Advantages includes the:

-breakdown of which sorts of inputs the test suit is unable to handle is provided by mutation scores.

-Early mistake detection to stop problems from entering the manufacturing stage.

-capacity to guarantee the test suite's and the source code's overall quality.



Yet, some of the drawbacks of mutation testing includes:

-Being a highly time-consuming procedure because it is quite extensive and requires time to analyse each test that was run on the programme.

-equivalent mutation might lead to a number of misunderstandings throughout the testing process.

-generally quite intimidating procedure because of the enormous quantity of testing and data that must be gathered in order to produce relevant programme insights.

# Explain your SELENUIM test case design process

# Explain the use of assertions and checkpoints

# how did you test each functionaity with different test data

# Discuss advantages and disadvantages of Selenium vs. Sikulix
Advantages of Selenium: It supports multiple web-browsers including chrome and safari.
Furthermore, it supports multiple languages including java, Ruby, Python,Ruby et cetera. 
Moreover,it can also be used with other tools including Jenkins and Maven.
Disadvantages of Selenium: It is mainly designed for web-applications not for desktop applications. 
Furthermore,it can be operated by users who knows how to write and execute testing scripts for the application, making it difficult for user with no programming experience to use this tool.
Advantages of Sikulix: It can be used for both desktop application testing and GUI testing.
Furthermore, as it used visual scripting, therefore the users does not need any coding experience for implementing this tool.
Disadvantages of Sikulix: It does not support various web-browsers making it less suitable for testing web applications.
Sikulix has a smaller community (actively using the tool) as compared to Selenium, therefore, the knowledge base is smaller as compared to Selenium.
# How the team work/effort was divided and managed
So the whole team was divided into two sub-teams. One team started working on the Mutation testing and on the GUI testing. After completing both the testing, each team explained the other team about the whole concept and all the team members tested each other's knowledge so as to assure that everybody has learnt each and every concept.
# Difficulties encountered, challenges overcome, and lessons learned
The main challenge we faced was to learn the new mutation tool : pitest and Selenium web-interface testing tool. We overcame this challenege as a team, we started persuing the links which were provided to us and then in addition to that we watched some youtube videos as well so as to understand the functionalities.
# Comments/feedback on the lab itself
This lab was the most interesting lab, all the work which had to be done was supported by the referenced links which made it really feasible for the students to understand everything and implement it.
