**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 â€“ Mutation Testing and Web app testing**

| Group \#:      |  12   |
| -------------- | --- |
| Student Names: | Shaila Aktar    |
| Student Names: | Muhammad Arij Ashar  |
| Student Names: | Mohammad Sadat Mohtasim   |
| Student Names: | Gaumit Kauts |

# Introduction


# Analysis of 10 Mutants of the Range class 
## Range.contains()
<img width="955" alt="contains" src="https://user-images.githubusercontent.com/90587576/225849035-7aec740d-9f4e-411e-95ac-e32b7a209e93.png">

## Range.expandToInclude()
<img width="952" alt="expandToInclude" src="https://user-images.githubusercontent.com/90587576/225849127-891c981e-f5f2-4219-9eea-02d5c53eac9d.png">

## Range.scale()
<img width="957" alt="scale" src="https://user-images.githubusercontent.com/90587576/225849149-dce601b7-a8db-4503-801f-6d94d5bf56ee.png">


# Report all the statistics and the mutation score for each test class
## Range statistics from Lab 03
<img width="843" alt="Screen Shot 2023-03-17 at 2 09 38 AM" src="https://user-images.githubusercontent.com/90587576/225849551-f1fb1e99-c004-44f9-bcb5-5ae9811a3113.png">

## Range statistics after adding more unit tests
<img width="836" alt="Screen Shot 2023-03-17 at 1 35 11 AM" src="https://user-images.githubusercontent.com/90587576/225849386-37ae5ad0-1e76-4269-8fdb-62aa8b69f72a.png">

## DataUtilities statistics from Lab 03
<img width="844" alt="Screen Shot 2023-03-17 at 2 56 58 PM" src="https://user-images.githubusercontent.com/90587576/226056267-8ef995de-d874-46c5-9e09-c048c1e05b67.png">

## DataUtilities statistics after adding more unit tests
<img width="838" alt="Screen Shot 2023-03-17 at 3 20 41 PM" src="https://user-images.githubusercontent.com/90587576/226056295-749d9080-c4cb-4c42-a0c7-b5ae15b589fc.png">


# Analysis drawn on the effectiveness of each of the test classes
Our mutation testing results indicate a noticeably greater efficacy for the Range and DataUtilities Classes. Range class's mutation coverage score improved by 28%, bringing the overall mutation coverage score up to 74%. The fact that our tests exceeded the requisite 10% increase specified at the markdown file demonstrates the lab's performance. These advancements in mutation testing aid in the detection of potential flaws and problems in the source code, which eventually results in a more reliable and practical software system. It's also crucial to keep in mind that as our mutation testing's coverage expands, it gets tougher to find mutations.
# A discussion on the effect of equivalent mutants on mutation score accuracy
Equivalent mutations are fundamentally distinct syntactically but semantically from the original code. Changing inequality signs or performing basic mathematical operations can be used to produce mutants that have the exact same logic as the originals, even if they are not expressed in the same way. Using analogous mutants will provide the developer with additional information on the calibre of his or her test suit because mutations are meant to replicate potential human faults or basic logical problems. Using that, they ought to be able to identify the unit test's shortcomings and, as a result, rectify them for a higher-quality end result.

Yet, if employed improperly, comparable mutants might artificially increase or deflate the accuracy of the testing suite. Equivalent mutations need to be utilised cautiously because they are just various ways of applying the same reasoning in the code. Coming back to the previous example, if we assume that each of the ten mutations is similar, then one test case would be sufficient to obtain a 100% mutation score, which may indicate a very high score and a programme that has been tested to the utmost extent. Nevertheless, not all potential paths have been explored, and the programme is not yet suitable for production.

Same to the previous situation, if all mutations are identical and the test suite does not cover the mutations, the mutation score may be 0%. As a result, while analogous mutations are important tools for evaluating the quality of the current mutations that have been used, they do have certain limitations that should be taken into account since they may result in inaccurate mutation ratings.

# A discussion of what could have been done to improve the mutation score of the test suites
The mutation score would increase overall if multiple mutants were killed while developing a test case. Also, we started focusing on functions with less coverage because there was a higher likelihood of boosting the overall mutation score on those. Throughout this process, we were also able to boost the scores to respectable levels. Given that mutations are frequently very slight changes that we occasionally forget to verify, such as an inequality error on an if statement condition, it is not difficult to ensure that the formula's outputs are accurate in certain circumstances.

# Why do we need mutation testing? Advantages and disadvantages of mutation testing
Implementing mutation testing is primarily done to improve the testing process' efficacy and, as a result, the software's quality. We may evaluate the efficiency and test coverage of the JUnit tests created for the application by making minor modifications to the source code. An efficient test suite would have a high mutation score, indicating that the code was being thoroughly evaluated while being exposed to a wide range of inputs.


Some of the Advantages includes the:

-breakdown of which sorts of inputs the test suit is unable to handle is provided by mutation scores.

-Early mistake detection to stop problems from entering the manufacturing stage.

-capacity to guarantee the test suite's and the source code's overall quality.



Yet, some of the drawbacks of mutation testing includes:

-Being a highly time-consuming procedure because it is quite extensive and requires time to analyse each test that was run on the programme.

-equivalent mutation might lead to a number of misunderstandings throughout the testing process.

-generally quite intimidating procedure because of the enormous quantity of testing and data that must be gathered in order to produce relevant programme insights.

# Explain your SELENUIM test case design process
For the Selenium test, the group decided to use the Amazon website. In order to test all potential data inputs we started analyzing and finalized the requirements that needed to be tested, then the team first attempted to login with an invalid email, then with an invalid password, and finally with a legitimate email and password. Afterwards, the team did some testing by searching for valid and invalid products on their platform. The team then started adding and removing things from the shopping cart to see how this worked in their system and if there were any errors as a result of the testing.{The team had a written list of potential outputs and guaranteed outputs}. Wish lists were developed by the team to improve that testing and act as a list of things users might be interested in saving for later. The group anticipated that all experiments would succeed given the popularity of Amazon. Furthermore, to help users navigate the test cases and further explain the findings, a readme file was uploaded.
# Explain the use of assertions and checkpoints
Assertions and checkpoints were considered unnecessary because we were using the Selenium IDE, which was already tracking the statements that were being executed. A green check mark appears next to the statements after they have been successfully performed in this case, signifying success. In order to use Selenium successfully, assertions and checkpoints are necessary. A test case's actual results can be compared to what the system predicted using assertions, which, on the one hand, enables developers to confirm anticipated outputs. This makes it easier to find problems or bugs in the program code. To implement assertions, Selenium's Assert class offers a number of functions including assertEquals(), assertTrue(), and assertFalse(). Contrarily, during the course of a test, checkpoints confirm the present state of a web page or application. They are used to check things like whether a particular web element is present, what the value of a field is, or the URL of a web website. Checkpoints can be implemented using functions from the WebDriver class, such as getTitle(), getCurrentUrl(), and getText().
# how did you test each functionaity with different test data
After defining the test cases, we started testing each functionality with different data sets: for instance, for a login{successful and unsuccessful case} test we inititated with different sets of inputs: like wrong email, incorrect password and blank password. Furthermore, for some test cases like adding a item into cart or wishlist and searchin an item, our team generated different input commands which searched and added items which were not present in the amazon database, items which were avaialble at Amazon and we even searched random-generated words which are not considered to be a physical item just to test if the search algorithm of Amazon would recognize and give an output accordingly. In addition to all of this we changed the language of amazon website to french and then ran our tests too. Overall, there were no such data sets that could have been created initially but our team tried and made some data sets as inputs to test the website {for a better testing practise}.
# Discuss advantages and disadvantages of Selenium vs. Sikulix
Advantages of Selenium: It supports multiple web-browsers including chrome and safari.
Furthermore, it supports multiple languages including java, Ruby, Python,Ruby et cetera. 
Moreover,it can also be used with other tools including Jenkins and Maven.

Disadvantages of Selenium: It is mainly designed for web-applications not for desktop applications. 
Furthermore,it can be operated by users who knows how to write and execute testing scripts for the application, making it difficult for user with no programming experience to use this tool.

Advantages of Sikulix: It can be used for both desktop application testing and GUI testing.
Furthermore, as it used visual scripting, therefore the users does not need any coding experience for implementing this tool.

Disadvantages of Sikulix: It does not support various web-browsers making it less suitable for testing web applications.
Sikulix has a smaller community (actively using the tool) as compared to Selenium, therefore, the knowledge base is smaller as compared to Selenium.
# How the team work/effort was divided and managed
So the whole team was divided into two sub-teams. One team started working on the Mutation testing and on the GUI testing. After completing both the testing, each team explained the other team about the whole concept and all the team members tested each other's knowledge so as to assure that everybody has learnt each and every concept.
# Difficulties encountered, challenges overcome, and lessons learned
The main challenge we faced was to learn the new mutation tool : pitest and Selenium web-interface testing tool. We overcame this challenege as a team, we started persuing the links which were provided to us and then in addition to that we watched some youtube videos as well so as to understand the functionalities.
# Comments/feedback on the lab itself
This lab was the most interesting lab, all the work which had to be done was supported by the referenced links which made it really feasible for the students to understand everything and implement it.
