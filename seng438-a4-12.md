**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#4 â€“ Mutation Testing and Web app testing**

| Group \#:      |  12   |
| -------------- | --- |
| Student Names: | Shaila Aktar    |
| Student Names: | Muhammad Arij Ashar  |
| Student Names: | Mohammad Sadat Mohtasim   |
| Student Names: | Gaumit Kauts |

# Introduction


# Analysis of 10 Mutants of the Range class 
## Range.contains()
<img width="955" alt="contains" src="https://user-images.githubusercontent.com/90587576/225849035-7aec740d-9f4e-411e-95ac-e32b7a209e93.png">

## Range.expandToInclude()
<img width="952" alt="expandToInclude" src="https://user-images.githubusercontent.com/90587576/225849127-891c981e-f5f2-4219-9eea-02d5c53eac9d.png">

## Range.scale()
<img width="957" alt="scale" src="https://user-images.githubusercontent.com/90587576/225849149-dce601b7-a8db-4503-801f-6d94d5bf56ee.png">


# Report all the statistics and the mutation score for each test class
## Range statistics from Lab 03
<img width="843" alt="Screen Shot 2023-03-17 at 2 09 38 AM" src="https://user-images.githubusercontent.com/90587576/225849551-f1fb1e99-c004-44f9-bcb5-5ae9811a3113.png">

## Range statistics after adding more unit tests
<img width="836" alt="Screen Shot 2023-03-17 at 1 35 11 AM" src="https://user-images.githubusercontent.com/90587576/225849386-37ae5ad0-1e76-4269-8fdb-62aa8b69f72a.png">

## DataUtilities statistics from Lab 03

## DataUtilities statistics after adding more unit tests

# Analysis drawn on the effectiveness of each of the test classes
Our mutation testing results indicate a noticeably greater efficacy for the Range and DataUtilities Classes. Range class's mutation coverage score improved by 35%, bringing the overall mutation coverage score up to 76%. The fact that our tests exceeded the requisite 10% increase specified at the markdown file demonstrates the lab's performance. These advancements in mutation testing aid in the detection of potential flaws and problems in the source code, which eventually results in a more reliable and practical software system. It's also crucial to keep in mind that as our mutation testing's coverage expands, it gets tougher to find mutations.
# A discussion on the effect of equivalent mutants on mutation score accuracy
Equivalent mutations are fundamentally distinct syntactically but semantically from the original code. Changing inequality signs or performing basic mathematical operations can be used to produce mutants that have the exact same logic as the originals, even if they are not expressed in the same way. Using analogous mutants will provide the developer with additional information on the calibre of his or her test suit because mutations are meant to replicate potential human faults or basic logical problems. Using that, they ought to be able to identify the unit test's shortcomings and, as a result, rectify them for a higher-quality end result.

Yet, if employed improperly, comparable mutants might artificially increase or deflate the accuracy of the testing suite. Equivalent mutations need to be utilised cautiously because they are just various ways of applying the same reasoning in the code. Coming back to the previous example, if we assume that each of the ten mutations is similar, then one test case would be sufficient to obtain a 100% mutation score, which may indicate a very high score and a programme that has been tested to the utmost extent. Nevertheless, not all potential paths have been explored, and the programme is not yet suitable for production.

Same to the previous situation, if all mutations are identical and the test suite does not cover the mutations, the mutation score may be 0%. As a result, while analogous mutations are important tools for evaluating the quality of the current mutations that have been used, they do have certain limitations that should be taken into account since they may result in inaccurate mutation ratings.

# A discussion of what could have been done to improve the mutation score of the test suites
The mutation score would increase overall if multiple mutants were killed while developing a test case. Also, we started focusing on functions with less coverage because there was a higher likelihood of boosting the overall mutation score on those. Throughout this process, we were also able to boost the scores to respectable levels. Given that mutations are frequently very slight changes that we occasionally forget to verify, such as an inequality error on an if statement condition, it is not difficult to ensure that the formula's outputs are accurate in certain circumstances.

# Why do we need mutation testing? Advantages and disadvantages of mutation testing
Implementing mutation testing is primarily done to improve the testing process' efficacy and, as a result, the software's quality. We may evaluate the efficiency and test coverage of the JUnit tests created for the application by making minor modifications to the source code. An efficient test suite would have a high mutation score, indicating that the code was being thoroughly evaluated while being exposed to a wide range of inputs.


Some of the Advantages includes the:

-breakdown of which sorts of inputs the test suit is unable to handle is provided by mutation scores.

-Early mistake detection to stop problems from entering the manufacturing stage.

-capacity to guarantee the test suite's and the source code's overall quality.



Yet, some of the drawbacks of mutation testing includes:

-Being a highly time-consuming procedure because it is quite extensive and requires time to analyse each test that was run on the programme.

-equivalent mutation might lead to a number of misunderstandings throughout the testing process.

-generally quite intimidating procedure because of the enormous quantity of testing and data that must be gathered in order to produce relevant programme insights.

# Explain your SELENUIM test case design process

# Explain the use of assertions and checkpoints

# how did you test each functionaity with different test data

# Discuss advantages and disadvantages of Selenium vs. Sikulix

# How the team work/effort was divided and managed


# Difficulties encountered, challenges overcome, and lessons learned

# Comments/feedback on the lab itself
